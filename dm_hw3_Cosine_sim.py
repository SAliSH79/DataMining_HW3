# -*- coding: utf-8 -*-
"""DM_HW3_9731306_SeyedAliSeyedHosseini (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1T9FHWH4QrIcsY4pdMBqch1AMO8NwxGEU

# HW3 of Data Mining, Programming task

### Reading dataset and examine it
"""

import pandas as pd #for manipulating and reading the csv dataset
import numpy as np
data = pd.read_csv("data.csv")
data.head() #Showing some rows of the dataset

data.shape

"""### Similarity Matrices"""

x = data['x']

y = data['y']
y.shape

"""##### Cosine distance"""

from sklearn.metrics.pairwise import cosine_similarity
Cosine_M = cosine_similarity(data)
for j in Cosine_M:
    print('\t'.join(map(str, j)))

Cosine_M.shape

"""##### Euclidean distance"""

from sklearn.metrics.pairwise import euclidean_distances
Euc_D = euclidean_distances(data)
for i in Euc_D:
    print('\t'.join(map(str, i)))

Euc_D.shape

"""## Clustering
#### with Cosine Similarity
"""

import numpy as np

def getNumFeatures(dataSet):
    # Return the number of features in the dataset (assumes all points have the same number of features)
    return dataSet.shape[1]

def cosine_similarity(point1, point2): #a function to caculate cosine similarity between two points
    vector1 = np.array(point1)
    vector2 = np.array(point2)
    dot_product = np.dot(vector1, vector2)
    norm_vector1 = np.linalg.norm(vector1) #norm of a vector
    norm_vector2 = np.linalg.norm(vector2)
    similarity = dot_product / (norm_vector1 * norm_vector2)
    return similarity

def getRandomCentroids(numFeatures, k):
   #initialize centroids randomly based on the number of features and the desired number of clusters
    centroids = []
    for _ in range(k):
        centroid = np.random.rand(numFeatures) #The same 2nd column of Dataset
        #Randomly chosen centroids
        centroids.append(centroid)
    return centroids

def getLabels(dataSet, centroids):
    labels = []
    for point in dataSet:
        # Calculate cosine similarity between the point and each centroid
        similarities = [cosine_similarity(point, centroid) for centroid in centroids]
        # Assign the label of the closest centroid
        label = np.argmax(similarities) #maximum value of similarities means they
        #belong to that cluster
        labels.append(label)
    return labels
# getLabels and getCentroids functions to assign labels to
# each datapoint based on centroids and update the centroids based on the datapoint labels
def getCentroids(dataSet, labels, k):
  #we iterate over the number of clusters (k). For each cluster, we retrieve the
  #points belonging to that cluster based on their labels. Then, we calculate the
  #mean of those points to obtain the new centroid.
    centroids = []
    for i in range(k):
        cluster_points = [dataSet[j] for j in range(len(dataSet)) if labels[j] == i]
        centroid = np.mean(cluster_points, axis=0)
        centroids.append(centroid) #new centroid
    return centroids

def shouldStop(oldCentroids, centroids, iterations, maxIterations):
  #the shouldStop function checks two conditions for stopping the iteration:
  #if the maximum number of iterations (maxIterations) has been reached and (2)
  #if the centroids have converged
    if iterations >= maxIterations:
        return True
    if np.array_equal(oldCentroids, centroids):
        return True
    return False

iterations = 0
maxIterations = 100

# Function: K-Means
# -------------
# K-Means is an algorithm that takes in a dataset and a constant
# k and returns k centroids (which define clusters of data in the # dataset which are similar to one another).
def kmeans(dataSet, k):
  # Initialize centroids randomly
   numFeatures = getNumFeatures(dataSet)
   centroids = getRandomCentroids(numFeatures, k)
   # Initialize book keeping vars.
   iterations = 0
   oldCentroids = None
    # Run the main k-means algorithm
   while not shouldStop(oldCentroids, centroids, iterations, maxIterations):
       # Save old centroids for convergence test. Book keeping.
       oldCentroids = centroids
       iterations += 1
       # Assign labels to each datapoint based on centroids
       labels = getLabels(dataSet, centroids)
       # Assign centroids based on datapoint labels
       centroids = getCentroids(dataSet, labels, k)
# We can get the labels too by calling getLabels(dataSet, centroids)
   return centroids, labels

data_arr = data.values #turn our dataframe into numpy array
k = 4

final_centroids, final_labels = kmeans(data_arr, k)
print("Final Centroids:", final_centroids)
print("Final Labels:", final_labels)

"""### Plotting"""

import matplotlib.pyplot as plt

def plotClusters(dataSet, labels, centroids):
    # Create a scatter plot for each cluster
    #It creates a scatter plot for each cluster by iterating over unique labels
    #and using boolean indexing to retrieve the data points belonging to each cluster.
    for label in np.unique(labels):
        cluster_points = dataSet[labels == label]
        plt.scatter(cluster_points[:, 0], cluster_points[:, 1], label=f'Cluster {label}')
    # Plot the centroids
    plt.scatter(np.array(centroids)[:, 0], np.array(centroids)[:, 1], marker='x', color='black', label='Centroids')
    # Set plot title and labels
    plt.title('Cluster Plot using Cosine Similarity')
    plt.xlabel('X-axis')
    plt.ylabel('Y-axis')
    # Add legend
    plt.legend()
    plt.grid()
    # Show the plot
    plt.show()

plotClusters(data_arr, final_labels, final_centroids)

"""## Clustering
#### with Euclidean Similarity
"""